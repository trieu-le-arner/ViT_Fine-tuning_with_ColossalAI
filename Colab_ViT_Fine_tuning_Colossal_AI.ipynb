{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vryvksWz6L4W"
      },
      "source": [
        "- Name: Le Hong Trieu\n",
        "- Metric No.: A0057066A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZzJ_Gjz53bh"
      },
      "source": [
        "#### GitHub repository\n",
        "https://github.com/trieu-le-arner/ViT_Fine-tuning_with_ColossalAI.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8N1L-e5Vhkd"
      },
      "source": [
        "#### Instructions\n",
        "1. Upload the notebook namely \"Colab_ViT_Fine-tuning_Colossal-AI\" to Google Colab\n",
        "2. Choose T4 GPU runtime type (1 GPU)\n",
        "3. Run all the cells in the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkUPtHAyY_Q2"
      },
      "source": [
        "#### Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BQoL7KPWOnq",
        "outputId": "5cccd5c5-408d-420f-c225-8df4abcf9f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ViT_Fine-tuning_with_ColossalAI'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 21 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (26/26), 8.30 KiB | 2.77 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/ViT_Fine-tuning_with_ColossalAI\n",
            "Requirement already satisfied: colossalai>=0.1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.3.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.61.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.66.2)\n",
            "Requirement already satisfied: transformers>=4.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.38.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (3.7.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (13.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: fabric in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: contexttimer in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (1.11.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (2.6.4)\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (0.1.99)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.1.12->-r requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.13.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.0->-r requirements.txt (line 6)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.0->-r requirements.txt (line 6)) (0.15.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2024.2.2)\n",
            "Requirement already satisfied: invoke>=2.0 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: decorator>=5 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (5.1.1)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.10/dist-packages (from fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (1.2.14)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google->colossalai>=0.1.12->-r requirements.txt (line 1)) (4.12.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (2.5.35)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (20.25.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->colossalai>=0.1.12->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->colossalai>=0.1.12->-r requirements.txt (line 1)) (2.16.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->colossalai>=0.1.12->-r requirements.txt (line 1)) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->colossalai>=0.1.12->-r requirements.txt (line 1)) (1.0.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai>=0.1.12->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai>=0.1.12->-r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2->fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->colossalai>=0.1.12->-r requirements.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (4.1.2)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (42.0.5)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.1.12->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google->colossalai>=0.1.12->-r requirements.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai>=0.1.12->-r requirements.txt (line 1)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai>=0.1.12->-r requirements.txt (line 1)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->colossalai>=0.1.12->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.1.12->-r requirements.txt (line 1)) (2.22)\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf /content/ViT_Fine-tuning_with_ColossalAI\n",
        "!git clone https://github.com/trieu-le-arner/ViT_Fine-tuning_with_ColossalAI.git\n",
        "%cd /content/ViT_Fine-tuning_with_ColossalAI\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Soa4yeqz3-BY",
        "outputId": "104ed44b-7565-4991-9673-15d872b4ff59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ MODEL=google/vit-base-patch16-224\n",
            "+ OUTPUT_PATH=./output_model\n",
            "+ PLUGIN=gemini\n",
            "+ GRAD_CHECKPOINT=True\n",
            "+ GPUNUM=1\n",
            "+ BS=16\n",
            "+ LR=2e-4\n",
            "+ EPOCH=3\n",
            "+ WEIGHT_DECAY=0.05\n",
            "+ WARMUP_RATIO=0.3\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --model_name google/vit-base-patch16-224 --output_path ./output_model --plugin gemini --batch_size 16 --num_epoch 3 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 04:40:19.619457: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 04:40:19.619500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 04:40:19.755862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 04:40:21.569877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 04:40:22] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "preprocessor_config.json: 100%|██████████| 160/160 [00:00<00:00, 829kB/s]\n",
            "Downloading readme: 100%|██████████| 2.50k/2.50k [00:00<00:00, 13.5MB/s]\n",
            "Downloading data: 100%|██████████| 378M/378M [00:12<00:00, 30.9MB/s]\n",
            "Downloading data: 100%|██████████| 413M/413M [00:16<00:00, 24.8MB/s]\n",
            "Generating train split: 100%|██████████| 3680/3680 [00:02<00:00, 1828.96 examples/s]\n",
            "Generating test split: 100%|██████████| 3669/3669 [00:01<00:00, 1975.53 examples/s]\n",
            "Processing images...:   1%|▏         | 52/3680 [00:00<00:33, 108.14it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2459/3680 [00:23<00:21, 57.84it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:35<00:00, 103.23it/s]\n",
            "Processing images...:  64%|██████▎   | 2338/3669 [00:22<00:16, 80.24it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 104.09it/s]\n",
            "config.json: 100%|██████████| 69.7k/69.7k [00:00<00:00, 6.41MB/s]\n",
            "model.safetensors: 100%|██████████| 346M/346M [00:03<00:00, 102MB/s] \n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 04:42:15] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as gemini                   \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 38.727423906326294 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 240.22123384475708 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/zero/gemini/chunk/chunk.py:45: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return tensor.storage().size() == 0\n",
            "[04/10/24 04:46:56] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:39 train              \n",
            "                    INFO     colossalai - colossalai - INFO: Start finetuning                       \n",
            "Epoch [1]:  90%|████████▉ | 205/229 [01:18<00:08,  2.73it/s, loss=0.659]/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:854: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Epoch [1]: 100%|██████████| 229/229 [01:27<00:00,  2.62it/s, loss=0.45]\n",
            "Evaluation result for epoch 1:                     average_loss=0.5510,                     accuracy=0.8349.\n",
            "Epoch [2]: 100%|██████████| 229/229 [01:26<00:00,  2.64it/s, loss=0.299]\n",
            "Evaluation result for epoch 2:                     average_loss=0.4083,                     accuracy=0.8772.\n",
            "Epoch [3]: 100%|██████████| 229/229 [01:26<00:00,  2.64it/s, loss=0.00977]\n",
            "Evaluation result for epoch 3:                     average_loss=0.3043,                     accuracy=0.9080.\n",
            "[04/10/24 04:52:02] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:78 train              \n",
            "                    INFO     colossalai - colossalai - INFO: Finish finetuning                      \n",
            "                    INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:81 train              \n",
            "                    INFO     colossalai - colossalai - INFO: Saving model checkpoint to             \n",
            "                             ./output_model                                                         \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "CPU times: user 5.54 s, sys: 626 ms, total: 6.16 s\n",
            "Wall time: 11min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!bash train.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L8bDKMM_-r3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ccfb71-218b-46b8-f14b-43dfc83b7c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ MODEL=google/vit-base-patch16-224\n",
            "+ GRAD_CHECKPOINT=True\n",
            "+ GPUNUM=1\n",
            "+ MEMCAP=0\n",
            "+ LR=2e-4\n",
            "+ WEIGHT_DECAY=0.05\n",
            "+ WARMUP_RATIO=0.3\n",
            "+ for BS in 8 32\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin torch_ddp --batch_size 8 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 04:57:36.557712: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 04:57:36.557830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 04:57:36.572028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 04:57:38.727171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 04:57:40] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   2%|▏         | 63/3680 [00:01<00:59, 60.93it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2454/3680 [00:25<00:13, 91.16it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:36<00:00, 100.36it/s]\n",
            "Processing images...:  64%|██████▎   | 2332/3669 [00:22<00:11, 116.57it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:36<00:00, 100.80it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 04:58:57] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as torch_ddp                \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09688138961791992 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.11255955696105957 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "[04/10/24 04:58:58] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Benchmarking: 100%|██████████| 20/20 [00:06<00:00,  2.95it/s]\n",
            "[04/10/24 04:59:05] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 8 - Plugin: torch_ddp - Throughput: 23.6198 - Maximum memory usage\n",
            "                             per gpu: 1.73 GB.                                                      \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin torch_ddp_fp16 --batch_size 8 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 04:59:17.637586: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 04:59:17.637635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 04:59:17.639013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 04:59:18.819902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 04:59:19] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   2%|▏         | 58/3680 [00:00<00:32, 112.27it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2459/3680 [00:23<00:13, 89.79it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:35<00:00, 105.06it/s]\n",
            "Processing images...:  64%|██████▎   | 2337/3669 [00:23<00:12, 110.35it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:36<00:00, 101.68it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:00:34] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as torch_ddp_fp16           \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09617114067077637 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.1161508560180664 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "[04/10/24 05:00:35] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Benchmarking: 100%|██████████| 20/20 [00:02<00:00,  7.11it/s]\n",
            "[04/10/24 05:00:38] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 8 - Plugin: torch_ddp_fp16 - Throughput: 56.8228 - Maximum memory \n",
            "                             usage per gpu: 1.72 GB.                                                \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin low_level_zero --batch_size 8 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 05:00:51.450464: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 05:00:51.450598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 05:00:51.452420: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 05:00:52.966192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 05:00:53] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   1%|▏         | 55/3680 [00:00<00:34, 106.08it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2451/3680 [00:23<00:13, 90.55it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:34<00:00, 105.21it/s]\n",
            "Processing images...:  64%|██████▎   | 2338/3669 [00:22<00:14, 90.98it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 103.21it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:02:07] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as low_level_zero           \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09435653686523438 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.1049506664276123 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "[04/10/24 05:02:08] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Benchmarking: 100%|██████████| 20/20 [00:03<00:00,  5.25it/s]\n",
            "[04/10/24 05:02:12] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 8 - Plugin: low_level_zero - Throughput: 42.0017 - Maximum memory \n",
            "                             usage per gpu: 1.64 GB.                                                \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin gemini --batch_size 8 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 05:02:25.311521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 05:02:25.311569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 05:02:25.312921: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 05:02:26.525543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 05:02:27] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   1%|▏         | 52/3680 [00:00<00:33, 108.94it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2456/3680 [00:22<00:16, 74.98it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:34<00:00, 108.00it/s]\n",
            "Processing images...:  64%|██████▎   | 2334/3669 [00:22<00:11, 114.59it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 103.60it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:03:40] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as gemini                   \n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.13648247718811035 seconds\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.173292875289917 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/zero/gemini/chunk/chunk.py:45: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return tensor.storage().size() == 0\n",
            "[04/10/24 05:03:43] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking: 100%|██████████| 20/20 [00:07<00:00,  2.78it/s]\n",
            "[04/10/24 05:03:50] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 8 - Plugin: gemini - Throughput: 22.2007 - Maximum memory usage   \n",
            "                             per gpu: 663.05 MB.                                                    \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for BS in 8 32\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin torch_ddp --batch_size 32 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 05:04:04.557679: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 05:04:04.557838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 05:04:04.559868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 05:04:06.212678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 05:04:07] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   2%|▏         | 59/3680 [00:00<00:31, 113.76it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2458/3680 [00:23<00:13, 91.25it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:34<00:00, 105.28it/s]\n",
            "Processing images...:  64%|██████▎   | 2335/3669 [00:22<00:17, 75.73it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 102.71it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:05:21] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as torch_ddp                \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09383869171142578 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.11762142181396484 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "[04/10/24 05:05:22] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Benchmarking: 100%|██████████| 20/20 [00:25<00:00,  1.26s/it]\n",
            "[04/10/24 05:05:47] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 32 - Plugin: torch_ddp - Throughput: 25.3715 - Maximum memory     \n",
            "                             usage per gpu: 2.10 GB.                                                \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin torch_ddp_fp16 --batch_size 32 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 05:05:59.252624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 05:05:59.252666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 05:05:59.254127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 05:06:00.434689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 05:06:01] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   2%|▏         | 59/3680 [00:00<00:31, 114.08it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2455/3680 [00:23<00:13, 89.35it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:34<00:00, 105.38it/s]\n",
            "Processing images...:  64%|██████▎   | 2337/3669 [00:22<00:11, 111.91it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 102.56it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:07:15] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as torch_ddp_fp16           \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09763479232788086 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.1203157901763916 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "[04/10/24 05:07:16] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Benchmarking: 100%|██████████| 20/20 [00:08<00:00,  2.38it/s]\n",
            "[04/10/24 05:07:25] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 32 - Plugin: torch_ddp_fp16 - Throughput: 76.1189 - Maximum memory\n",
            "                             usage per gpu: 2.01 GB.                                                \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin low_level_zero --batch_size 32 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 05:07:38.425630: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 05:07:38.425686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 05:07:38.427096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 05:07:39.603150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 05:07:40] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   2%|▏         | 60/3680 [00:00<00:31, 115.81it/s]Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2458/3680 [00:23<00:13, 88.70it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:35<00:00, 104.79it/s]\n",
            "Processing images...:  64%|██████▍   | 2339/3669 [00:23<00:11, 111.61it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 101.97it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:08:55] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as low_level_zero           \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.09315276145935059 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.11391544342041016 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "[04/10/24 05:08:56] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/nvme_optimizer.py:55: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  numel += p.storage().size()\n",
            "Benchmarking: 100%|██████████| 20/20 [00:08<00:00,  2.33it/s]\n",
            "[04/10/24 05:09:04] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 32 - Plugin: low_level_zero - Throughput: 74.4609 - Maximum memory\n",
            "                             usage per gpu: 1.64 GB.                                                \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n",
            "+ for PLUGIN in \"torch_ddp\" \"torch_ddp_fp16\" \"low_level_zero\" \"gemini\"\n",
            "+ colossalai run --nproc_per_node 1 --master_port 29505 main.py --running_mode benchmark --model_name google/vit-base-patch16-224 --plugin gemini --batch_size 32 --mem_cap 0 --learning_rate 2e-4 --weight_decay 0.05 --warmup_ratio 0.3 --max_train_steps 20 --grad_checkpoint True\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/pipeline/schedule/_utils.py:19: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _register_pytree_node(OrderedDict, _odict_flatten, _odict_unflatten)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:254: UserWarning: <class 'collections.OrderedDict'> is already registered as pytree node. Overwriting the previous registration.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/shardformer/layer/normalization.py:45: UserWarning: Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\n",
            "  warnings.warn(\"Please install apex from source (https://github.com/NVIDIA/apex) to use the fused layernorm kernel\")\n",
            "2024-04-10 05:09:18.177890: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 05:09:18.177937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 05:09:18.179348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 05:09:19.371895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:48: UserWarning: `config` is deprecated and will be removed soon.\n",
            "  warnings.warn(\"`config` is deprecated and will be removed soon.\")\n",
            "[04/10/24 05:09:20] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /usr/local/lib/python3.10/dist-packages/colossalai/initialize.py:67    \n",
            "                             launch                                                                 \n",
            "                    INFO     colossalai - colossalai - INFO: Distributed environment is initialized,\n",
            "                             world size: 1                                                          \n",
            "Processing images...:   2%|▏         | 59/3680 [00:00<00:38, 94.92it/s] Skipping an image due to error!\n",
            "Processing images...:  67%|██████▋   | 2456/3680 [00:23<00:13, 90.29it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3680/3680 [00:35<00:00, 104.85it/s]\n",
            "Processing images...:  64%|██████▎   | 2333/3669 [00:22<00:11, 117.15it/s]Skipping an image due to error!\n",
            "Processing images...: 100%|██████████| 3669/3669 [00:35<00:00, 102.55it/s]\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([37]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([37, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[04/10/24 05:10:34] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:168 main              \n",
            "                    INFO     colossalai - colossalai - INFO: Set plugin as gemini                   \n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT cpu_adam_x86 kernel during runtime now\n",
            "[extension] Time taken to compile cpu_adam_x86 op: 0.10034894943237305 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/kernel/extensions/utils.py:96: UserWarning: [extension] The CUDA version on the system (12.2) does not match with the version (12.1) torch was compiled with. The mismatch is found in the minor version. As the APIs are compatible, we will allow compilation to proceed. If you encounter any issue when using the built kernel, please try to build it again with fully matched CUDA versions\n",
            "  warnings.warn(\n",
            "[extension] Compiling the JIT fused_optim_cuda kernel during runtime now\n",
            "[extension] Time taken to compile fused_optim_cuda op: 0.1265699863433838 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/nn/optimizer/hybrid_adam.py:90: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
            "/usr/local/lib/python3.10/dist-packages/colossalai/zero/gemini/chunk/chunk.py:45: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return tensor.storage().size() == 0\n",
            "[04/10/24 05:10:37] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:92 benchmark          \n",
            "                    INFO     colossalai - colossalai - INFO: Start benchmarking                     \n",
            "Benchmarking: 100%|██████████| 20/20 [00:10<00:00,  1.83it/s]\n",
            "[04/10/24 05:10:47] INFO     colossalai - colossalai - INFO:                                        \n",
            "                             /content/ViT_Fine-tuning_with_ColossalAI/main.py:112 benchmark         \n",
            "                    INFO     colossalai - colossalai - INFO: Benchmarking finished: - Batch size per\n",
            "                             gpu: 32 - Plugin: gemini - Throughput: 58.5107 - Maximum memory usage  \n",
            "                             per gpu: 663.05 MB.                                                    \n",
            "\n",
            "====== Training on All Nodes =====\n",
            "127.0.0.1: success\n",
            "\n",
            "====== Stopping All Nodes =====\n",
            "127.0.0.1: finish\n"
          ]
        }
      ],
      "source": [
        "!bash benchmark.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yllWppOONYJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}